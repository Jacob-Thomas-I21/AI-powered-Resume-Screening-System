# AI-Powered Resume Screening System

## ðŸ“Œ Project Overview
This project automates the resume screening process using Natural Language Processing (NLP) and Machine Learning (ML). The system extracts key information from resumes, ranks candidates based on job descriptions, and provides an AI-driven candidate shortlisting system.

---

## ðŸ“Š Current Project Progress

âœ… Phase 1: Data Preprocessing (Completed)

âœ… Step 1: Loaded Resume Dataset  
âœ… Step 2: Dropped Unnecessary Columns  
âœ… Step 3: Handled Missing Data  
âœ… Step 4: Cleaned Resume Text (Clean_Resume column)

âœ… Phase 2: Feature Extraction (Completed)

âœ… Step 5: Tokenization & Stopword Removal  
âœ… Step 6: Skill Extraction (NER)  
âœ… Step 7: Convert Text to Numerical Vectors (SBERT)  

âœ… Model Training & Resume Ranking (Completed)  
âœ… API & Deployment (In Progress)

---

## ðŸš€ Features

âœ… Resume Parsing â€“ Extracts structured information from PDF & DOCX resumes.  
âœ… Text Preprocessing â€“ Tokenization, stopword removal, Named Entity Recognition (NER).  
âœ… Skill Extraction â€“ Identifies relevant skills (Python, Java, Machine Learning, etc.).  
âœ… AI Model for Candidate Ranking â€“ Uses SBERT embeddings + MLP + XGBoost to match resumes to job descriptions.  
âœ… Deployment Ready â€“ Prepares FastAPI service for real-time predictions.  

---

## ðŸ“‚ Project Structure

resume-screening/
**â”œâ”€â”€ data/                           # Processed resumes, job descriptions & embeddings**

â”‚   â”œâ”€â”€ extracted_skills.csv        # Resume data with extracted skills

â”‚   â”œâ”€â”€ cleaned_job_descriptions.csv # Preprocessed job descriptions

â”‚   â”œâ”€â”€ train_data.npz               # Processed train features & labels

â”‚   â”œâ”€â”€ test_data.npz                # Processed test features & labels

â”‚   â”œâ”€â”€ job_embedding.npy            # SBERT embedding for job description

â”‚   â”œâ”€â”€ job_skills.pkl                # Extracted skill set from job description

**â”œâ”€â”€ models/                         # Trained machine learning models**

â”‚   â”œâ”€â”€ MLP_Model.keras              # Trained MLP model

â”‚   â”œâ”€â”€ XGBoost_Model.pkl            # Trained XGBoost model

**â”œâ”€â”€ notebooks/                      # Jupyter notebooks for experimentation**

â”‚   â”œâ”€â”€ data_processing.ipynb        # Preprocessing, skill extraction & SBERT embeddings

â”‚   â”œâ”€â”€ model_training.ipynb         # MLP + XGBoost training

â”‚   â”œâ”€â”€ api_deployment.ipynb         # Deployment testing (if any)

**â”œâ”€â”€ src/                            # Source code**

â”‚   â”œâ”€â”€ data_preprocessing,_skill_extraction_&_sbert_embeddings.py   # Full preprocessing + embedding pipeline

â”‚   â”œâ”€â”€ resume_match_deployment.py   # Full training process (MLP + XGBoost)

â”‚   â”œâ”€â”€ predict_resume_match.py      # Single resume prediction script (after deployment)

â”‚   â”œâ”€â”€ update_job_description.py    # New job description updater (manual trigger for retraining)

â”‚   â”œâ”€â”€ api.py                       # (To be created for FastAPI deployment)

â”œâ”€â”€ Dockerfile                      # Docker containerization (optional, for future)

â”œâ”€â”€ requirements.txt                # Dependencies list

â”œâ”€â”€ README.md                       # Project documentation

---

## **Technologies Used**

âœ… Programming Language: Python  
âœ… NLP Libraries: SpaCy, NLTK, Sentence Transformers  
âœ… Machine Learning: Scikit-learn, TensorFlow, XGBoost  
âœ… Deployment: FastAPI, Docker, AWS/GCP

---

## ðŸ“Œ Installation & Setup

### **Prerequisites**
- Python 3.8+
- Virtual environment (optional but recommended)
- Docker (if deploying in containers)

### **Step 1: Clone the Repository**
```bash
git clone https://github.com/yourusername/resume-screening.git
cd resume-screening

Step 2: Install Dependencies

pip install -r requirements.txt

ðŸ“Œ New Process - Add/Change Job Description
ðŸ†• Adding or Updating Job Description

    Run the new script:

    python update_job_description.py

    Paste the new job description when prompted.
    This will: âœ… Save job_description.csv
    âœ… Precompute & save job_embedding.npy
    âœ… Precompute & save job_skills.pkl

ðŸ”„ What to Do After Updating Job Description?

    Re-run Data Preprocessing for All Resumes:

python data_preprocessing,_skill_extraction_&_sbert_embeddings.py

Retrain the Models:

    python resume_match_deployment.py

ðŸ“Œ Process for New Resumes (Same Job Description)

    Add new resumes to your folder.
    Re-run:

    python data_preprocessing,_skill_extraction_&_sbert_embeddings.py
    python resume_match_deployment.py

ðŸ“Œ Process for New Resumes (Single Prediction After Deployment)

    After deployment, if a single new resume arrives, you donâ€™t need to retrain the entire model.
    Use:

    python predict_resume_match.py /path/to/new_resume.pdf

    This loads existing models and gives a result immediately.

ðŸ“Œ Running the API

Once fully trained and processed, you can run:

uvicorn api:app --reload

This serves the AI as a REST API for real-time predictions.
ðŸ“Œ License & Usage Restrictions

This project is NOT Open Source and is protected under a proprietary license.

You are NOT allowed to:

    Use, copy, modify, distribute, or resell this software without explicit permission from the author.
    Train a competing AI model based on this repository.

Permitted Uses (Only if you receive written approval):

    Research and academic purposes.
    Enterprise use with a purchased license.

For licensing inquiries, contact:

    Email: jacobtjoshy@gmail.com
    GitHub: Jacob-Thomas-I21

Unauthorized use, reproduction, or modification of this project may result in legal action.

Legal Notice This project is protected under international copyright laws.
Any unauthorized commercial use, reselling, or redistribution is strictly prohibited.
**Legal Notice**

This project is protected under international copyright laws.

Any unauthorized commercial use, reselling, or redistribution is strictly prohibited.
